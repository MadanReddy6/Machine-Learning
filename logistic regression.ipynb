{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.nn import sigmoid\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('recruitment_data.csv')\n",
    "\n",
    "df.drop(['RecruitmentStrategy'], axis=1,inplace= True)\n",
    "df['HiringDecision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making lables frequecy same to avoid bias\n",
    "for HiringDecision , h_df in df.groupby('HiringDecision'):\n",
    "    if len(h_df) < 400:\n",
    "        df.drop(h_df.index,axis=0 , inplace= True)\n",
    "        \n",
    "    elif len(h_df) > 465:\n",
    "        x = len(h_df) - 465\n",
    "        df.drop(h_df[ :x].index, axis= 0 , inplace=True)\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "x= df[[\"Age\",\"EducationLevel\",\"ExperienceYears\",\"PreviousCompanies\",\"DistanceFromCompany\",\"InterviewScore\",\"PersonalityScore\",\"HiringDecision\"]]\n",
    "org_mean , org_std = x.mean() , x.std()\n",
    "\n",
    "df[[\"Age\",\"EducationLevel\",\"ExperienceYears\",\"PreviousCompanies\",\"DistanceFromCompany\",\"InterviewScore\",\"PersonalityScore\",\"HiringDecision\"]]= ( x - org_mean)/ org_std\n",
    "\n",
    "targets = df[[\"HiringDecision\"]]\n",
    "input = df.drop([\"HiringDecision\"] , axis=1)\n",
    "\n",
    "input.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting into tensors\n",
    "inputs_tf=tf.constant(input, dtype= tf.float64)\n",
    "targets_tf = tf.constant(targets , dtype= tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the mode\n",
    "weights = tf.Variable(tf.random.normal(shape=(9,1),dtype= tf.float64))\n",
    "bias = tf.Variable(tf.random.normal(shape=(1,),dtype= tf.float64)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main training loop \n",
    "lr = 0.001\n",
    "mean_losses = []   \n",
    "epochs = range(1000)\n",
    "for epochs in tqdm(epochs):\n",
    " \n",
    "    with tf.GradientTape() as tape:\n",
    "        #making prediction\n",
    "        # preds = tf.add(inputs_tf , weights , bias)\n",
    "        preds = tf.add(tf.matmul(inputs_tf , weights), bias)\n",
    "        prob= sigmoid(preds)\n",
    "        \n",
    "        #calculation loss \n",
    "        loss = binary_crossentropy(targets_tf, prob)\n",
    "        mean_loss = tf.reduce_sum(loss)/len(targets_tf)\n",
    "        \n",
    "        print(f\" for {epochs} epochs ,  mean loss is {mean_loss} \")\n",
    "        #taking gradiants\n",
    "        w_grad , b_grad = tape.gradient(mean_loss, [ weights, bias])\n",
    "        \n",
    "        #updating model\n",
    "        weights = tf.Variable(weights - lr * w_grad)\n",
    "        bias = tf.Variable(bias - lr * b_grad)\n",
    "\n",
    "\n",
    "print(mean_losses)\n",
    "plt.plot(epochs, mean_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.title('Mean Loss over Epochs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_losses.shape)\n",
    "# print(epochs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0 \n",
    "predictions = inputs_tf @ weights + bias\n",
    "prob = sigmoid(predictions) \n",
    "\n",
    "for i in range(len(prob)):\n",
    "    if prob[i] > 0.5: \n",
    "        if int (targets_tf[i]) == 1: \n",
    "           correct += 1      \n",
    "\n",
    "    else:\n",
    "        if int(targets_tf[i]) == 0:\n",
    "            correct +=1\n",
    "            \n",
    "correct/len(prob)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "predictions = tf.round(prob)\n",
    "correct_predictions = tf.equal(predictions, targets_tf)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float64))\n",
    "\n",
    "print(f\"Epoch {epochs}: Accuracy = {accuracy.numpy() * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
